{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5024cb21-7c12-44b5-809b-8994e2744e60",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports e Funções"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import lit\n",
    "import json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, TimestampType\n",
    "from delta import DeltaTable\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\"../lib/\")     \n",
    "sys.path.append(f'/Workspace/Users/{dbutils.widgets.get(\"account\")}/music_data_lake/src/lib/')                                                                                                        \n",
    "from utils import get_schema, table_exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2d12b6-da67-4e3c-a54b-f74142047020",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup"
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"bronze\"\n",
    "schema = \"music_data\"\n",
    "tablename = dbutils.widgets.get(\"tablename\")\n",
    "table_schema = tablename\n",
    "primary_key = dbutils.widgets.get(\"primary_key\")\n",
    "timestamp_field = \"ts_ms\"\n",
    "\n",
    "if not table_exists(spark, catalog=catalog, schema=schema, table=tablename):\n",
    "    print(\"Tabela não existente, criando...\")\n",
    "\n",
    "    df_full = spark.read.format(\"parquet\").load(f'/Volumes/raw/music_data/full_load/{tablename}/')\n",
    "\n",
    "    (df_full.coalesce(1)\n",
    "            .write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .saveAsTable(f'{catalog}.{schema}.{tablename}')\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"Tabela {tablename} já existente, ignorando full-load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c1c369-31ad-4f70-bf07-45b902bda624",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Obtendo schema da tabela a ser processada"
    }
   },
   "outputs": [],
   "source": [
    "# Define o esquema esperado para os arquivos de CDC\n",
    "\n",
    "with open(f\"/Workspace/Users/mydatabrickstestacc@gmail.com/music_data_lake/src/{catalog}/music_data_schemas.json\", \"r\") as file:\n",
    "    schema_data = json.load(file)\n",
    "\n",
    "try:\n",
    "    cdc_schema = get_schema(schema_name=table_schema, schema_json=schema_data)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f85a2ee-3628-45ed-9c6a-6716f80dae99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caminhos dos arquivos Parquet\n",
    "df_cdc = (spark.read\n",
    "              .format(\"parquet\")\n",
    "              .load(f\"/Volumes/raw/music_data/cdc/postgres.public.{tablename}/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f01feb12-3397-42a3-b33b-2f3e4f8619ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if df_cdc.isEmpty():\n",
    "    print(\"Nenhum dado encontrado para processar. Finalizando o fluxo.\")\n",
    "else:\n",
    "    df_cdc.createOrReplaceGlobalTempView(f\"view_{tablename}\")  \n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM view_{tablename}\n",
    "        WHERE {primary_key} IS NOT NULL\n",
    "        QUALIFY ROW_NUMBER() OVER (PARTITION BY {primary_key} ORDER BY {timestamp_field} DESC) = 1\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df_cdc = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63350ef5-0eb2-4f9a-9a93-bc9bfa661787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze = DeltaTable.forName(spark, f\"{catalog}.{schema}.{tablename}\")\n",
    "    \n",
    "# Realizar o MERGE combinando upsert e delete\n",
    "(bronze.alias(\"target\")\n",
    "        .merge(df_cdc.alias(\"source\"), f\"target.{primary_key} = source.{primary_key}\")\n",
    "        .whenMatchedDelete(condition = \"source.operation = 'd'\")\n",
    "        .whenMatchedUpdateAll(condition = \"source.operation = 'u'\")\n",
    "        .whenNotMatchedInsertAll(condition = \"source.operation = 'c' OR source.operation = 'u'\")\n",
    "        .execute()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
